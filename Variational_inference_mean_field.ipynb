{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational inference (mean field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cse.buffalo.edu/faculty/mbeal/papers/beal03.pdf\n",
    "https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf\n",
    "http://www.maths.usyd.edu.au/u/jormerod/JTOpapers/Ormerod10.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing mean-field approximation, we enforce independence between groups of or all of the unobserved variables. If we (are willing to) pick conjugate priors, then it is possible to derive closed-form updates for the approximation functions $q$ of each of the model parameter groups. We can iterate through the groups to update the parameters given the current estimate of all other parameter groups.\n",
    "\n",
    "TODO: Understand when this is a good assumption. I think whenever dependence is not strong in the first place and when dependence is strong only in places with low probability mass?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great blog showing the general derviation of mean-field approximation: https://bjlkeng.github.io/posts/variational-bayes-and-the-mean-field-approximation/\n",
    "See derivations --> \n",
    "\n",
    "$q_j(\\theta_j) = e^{E_{m|m \\neq n}[log p(\\theta, X)]} \\cdot \\frac{1}{Z_j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 10\n",
    "tau = 1/2\n",
    "X = np.random.normal(mu, scale = 1/np.sqrt(tau), size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.011185680581566\n",
      "1.9950700561309764\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X))\n",
    "print(np.var(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add step-by-step derivations from notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside \n",
    "Completing the square:\n",
    "https://en.wikipedia.org/wiki/Completing_the_square\n",
    "\n",
    "$x^2 + bx +c = (x + \\frac{b}{2})^2 + (c- \\frac{b^2}{4})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mu(X, mu_0, lambda_0):\n",
    "    N = len(X)\n",
    "    mu = (np.sum(X) - 2*lambda_0*mu_0) / (N+lambda_0)\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tau(X, lambda_0, alpha, beta):\n",
    "    tau = (lambda_0 + len(X)) * alpha/beta\n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha(alpha_0, X):\n",
    "    N = len(X)\n",
    "    alpha_tau = alpha_0 + 0.5*(N+1)\n",
    "    return alpha_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beta(beta_0, mu_0, mu, tau, lambda_0, X):\n",
    "    N = len(X)\n",
    "    E_mu2 = 1/tau + mu**2\n",
    "    beta_tau = beta_0 +0.5*lambda_0*(E_mu2-2*mu_0*mu+mu_0**2) \\\n",
    "                    +0.5*np.sum((X**2) - 2*mu*X +E_mu2)\n",
    "    return beta_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10026.975877905272"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_beta(1,0,10,100,0,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_VB(start_values, hyperparameter, n_iter):\n",
    "    # Initialize output array\n",
    "    trace = np.empty([n_iter,4])\n",
    "    # Unpack input parameters\n",
    "    mu, tau, alpha, beta = (start_values[x] for x in [\"mu\",\"tau\",\"alpha\",\"beta\"])\n",
    "    X, mu_0, lambda_0, alpha_0, beta_0 = (hyperparameter[x] for x in [\"X\", \"mu_0\",\"lambda_0\",\"alpha_0\",\"beta_0\"])\n",
    "    \n",
    "    # These variables don't depend on changing variables\n",
    "    mu = update_mu(X, mu_0, lambda_0)\n",
    "    alpha = update_alpha(alpha_0, X)\n",
    "    \n",
    "    # Iteratively update the other variables\n",
    "    for it in range(n_iter):\n",
    "        tau = update_tau(X, lambda_0, alpha, beta)\n",
    "        beta = update_beta(beta_0, mu_0, mu, tau, lambda_0, X)\n",
    "        # Save values per iteration\n",
    "        trace[it,:] = (mu,tau,alpha,beta)\n",
    "    \n",
    "    return trace\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_values = {\n",
    "    \"mu\":0,\n",
    "    \"tau\":2,\n",
    "    \"alpha\":10,\n",
    "    \"beta\":10,\n",
    "}\n",
    "\n",
    "hyperparameter = {\n",
    "    \"X\":X,\n",
    "    \"mu_0\":0,\n",
    "    \"lambda_0\":1/np.sum(np.square(X)), # Related to var(beta_OLS)?\n",
    "    \"alpha_0\":2,\n",
    "    \"beta_0\":1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = run_VB(start_values, hyperparameter, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10.01118568 5013.85760844 5002.5        9977.34756582]]\n"
     ]
    }
   ],
   "source": [
    "print(trace[-1:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 0.501\n",
      "10 0.5\n"
     ]
    }
   ],
   "source": [
    "result = trace[-1,:]\n",
    "print(round(result[0]), # Expectation of the Normal distribution for mu\n",
    "      round(result[2]/result[3],3)) # Expectation of the Gamma distribution for tau\n",
    "print(mu, tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Bayes for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivation: https://arxiv.org/pdf/1310.5438v2.pdf\n",
    "\n",
    "Comparison to frequentiest motivation: https://onlinecourses.science.psu.edu/stat857/node/155/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Everyone seems to assume $\\tau_{beta} = \\lambda \\tau$. I see where that gets convenient in the derivation, but shouldn't it work without, too? What's the difference in meaning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple 1-D regression case (without constant)\n",
    "beta_true = 2\n",
    "tau_true = 1\n",
    "n_obs = 10000\n",
    "X = np.random.uniform(-4,4, size =n_obs)\n",
    "y = beta_true*X + np.random.normal(0,1/np.sqrt(tau_true), size = len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_alpha(alpha_0, X):\n",
    "    N = len(X)\n",
    "    alpha_tau = alpha_0 + 0.5*N\n",
    "    return alpha_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beta(beta_0, mu, tau_beta, X):\n",
    "    E_mu2 = 1/tau_beta + mu**2\n",
    "    beta_tau = beta_0 +0.5*(np.dot(y,y)-2*mu*np.dot(y,X)+E_mu2*np.dot(X,X.T))\n",
    "    return beta_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mu(X,y, alpha, beta, tau_beta_0):\n",
    "    E_tau = alpha/beta\n",
    "    mu =  E_tau * np.dot(y,X) / (E_tau *np.dot(X.T,X) + tau_beta_0)\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tau_beta(X, tau_beta_0, alpha, beta):\n",
    "    tau_beta = (tau_beta_0 + np.dot(X.T,X)) * alpha/beta\n",
    "    return tau_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_VB(start_values, hyperparameter, n_iter):\n",
    "    # Initialize output array\n",
    "    trace = np.empty([n_iter,4])\n",
    "    # Unpack input parameters\n",
    "    mu, tau_beta, alpha, beta = (start_values[x] for x in [\"mu\",\"tau_beta\",\"alpha\",\"beta\"])\n",
    "    X,y, tau_beta_0, alpha_0, beta_0 = (hyperparameter[x] for x in [\"X\",\"y\", \"tau_beta_0\",\"alpha_0\",\"beta_0\"])\n",
    "    \n",
    "    # These variables don't depend on changing variables\n",
    "    alpha = update_alpha(alpha_0, X)\n",
    "    \n",
    "    # Iteratively update the other variables\n",
    "    for it in range(n_iter):\n",
    "        mu = update_mu(X,y, alpha, beta, tau_beta_0)\n",
    "        tau_beta = update_tau_beta(X, tau_beta_0, alpha, beta)\n",
    "        beta = update_beta(beta_0, mu, tau_beta, X)\n",
    "        # Save values per iteration\n",
    "        trace[it,:] = (mu,tau_beta,alpha,beta)\n",
    "    \n",
    "    return trace\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_values = {\n",
    "    \"mu\":0,\n",
    "    \"tau_beta\":2,\n",
    "    \"alpha\":10,\n",
    "    \"beta\":10,\n",
    "}\n",
    "\n",
    "hyperparameter = {\n",
    "    \"X\":X,\n",
    "    \"y\":y,\n",
    "    \"tau_beta_0\":1,\n",
    "    \"alpha_0\":2,\n",
    "    \"beta_0\":1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = run_VB(start_values, hyperparameter, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.99973285e+00 5.37780795e+04 5.00200000e+03 4.94835491e+03]\n"
     ]
    }
   ],
   "source": [
    "print(trace[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 1.0\n",
      "2 1\n"
     ]
    }
   ],
   "source": [
    "result = trace[-1,:]\n",
    "print(round(result[0]), # Expectation of the Normal distribution for mu\n",
    "      round(result[2]/result[3])) # Expectation of the Gamma distribution for tau\n",
    "print(beta_true, tau_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Extend derivation and code to multivariate case. If we assume that all beta priors are identical, then do this in matrix notation and code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pymc]",
   "language": "python",
   "name": "Python [pymc]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
