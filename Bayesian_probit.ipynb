{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # fast standard math capabilities\n",
    "import pandas as pd # easy data handling\n",
    "from sklearn.model_selection import train_test_split # scikit-learn for ML\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt # Useful for plotting\n",
    "import seaborn as sns # Advanced plots\n",
    "\n",
    "import edward as ed \n",
    "from edward.models import Normal, Bernoulli, Empirical\n",
    "from edward.inferences import MetropolisHastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv data using pandas\n",
    "bank_choice = pd.read_csv(\"/Users/hauptjoh/Downloads/bank_choice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_train, choice_test = train_test_split(bank_choice, test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = choice_train[[\"choice\"]].values.flatten()\n",
    "X_train = choice_train.drop([\"choice\", \"id\"], axis = 1).values\n",
    "\n",
    "y_test = choice_test[[\"choice\"]].values.flatten()\n",
    "X_test = choice_test.drop([\"choice\", \"id\"], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = y_train.shape[0] # Number of observations\n",
    "D = X_train.shape[1] # Number of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.59500819  3.10176761  2.01029561 -0.05008957 -0.47475756 -0.59287675\n",
      "   1.27482891  2.43007257 -0.09189518 -1.33641466  0.8876274   1.51297273\n",
      "   0.58670077  1.90118752]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression with scikit-learn\n",
    "from sklearn import linear_model\n",
    "logit = linear_model.LogisticRegression(penalty=\"l2\", C=1)\n",
    "logit.fit(X=X_train, y=y_train)\n",
    "# Print out the estimated coefficients\n",
    "print(logit.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If things go wrong, it's useful to reset the graph and start fresh\n",
    "# without having to restart the kernel\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random number generator seed for replicable results\n",
    "ed.set_seed(42) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow placeholder for matrix of float numbers with dimensions [N, D]\n",
    "X = tf.placeholder(tf.float32, [N, D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Normal(loc=tf.zeros(D), scale=1.0 * tf.ones(D))\n",
    "b = Normal(loc=tf.zeros([]), scale=1.0 * tf.ones([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Probit model works by assuming that the values are normally distributed (imagine utility) and that the decision depends on the sign of the value. For example, the utility of a product to the customer depends on the attributes of the customer, product and situation expressed in X. If the utility is >0, then we observe a purchase. If it is <0, then the customer decides not to buy (or buy something else)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This looks intuitive but doesn't work. I think the tf.greater() breaks the code\n",
    "# Doing inference on z directly w.r.t y_train gives approx. same AUC as logit\n",
    "z = Normal(loc = ed.dot(X,w) +b, scale=1.)\n",
    "y = tf.greater(z, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different activation function here, see Bishop 4.3 for details\n",
    "y = Bernoulli(probs = 0.5 * (1 + tf.erf(ed.dot(X,w) / tf.sqrt(2.))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_w = Normal(loc=w, scale = 0.05)\n",
    "proposal_b = Normal(loc=b, scale = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10000 # Number of iterations\n",
    "qw = Empirical(tf.Variable(tf.zeros([T,D])))\n",
    "qb = Empirical(tf.Variable(tf.zeros([T,])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hauptjoh/anaconda/envs/edward/lib/python3.6/site-packages/edward/util/random_variables.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  not np.issubdtype(value.dtype, np.float) and \\\n",
      "/Users/hauptjoh/anaconda/envs/edward/lib/python3.6/site-packages/edward/util/random_variables.py:53: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  not np.issubdtype(value.dtype, np.int) and \\\n"
     ]
    }
   ],
   "source": [
    "inference = MetropolisHastings({w:qw, b:qb}, \n",
    "                               {w:proposal_w, b:proposal_b},\n",
    "                               data={y:y_train, X:X_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [100%] ██████████████████████████████ Elapsed: 19s | Acceptance Rate: 0.005\n"
     ]
    }
   ],
   "source": [
    "inference.run(n_print=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model criticism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients of the logit and probit model are not the same [TODO: Should they be? No, need to be transformed by a factor of 1.6?]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47404978\n",
      "[-0.04339837]\n"
     ]
    }
   ],
   "source": [
    "b_est = np.median(qb.sample(10000).eval())\n",
    "print(b_est)\n",
    "print(logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3088462   0.6198552   0.38394704 -0.01282695 -0.10555348 -0.11564795\n",
      "  0.23597543  0.4708846  -0.02196553 -0.2759533   0.1495438   0.24991529\n",
      "  0.1110389   0.33218917]\n",
      "[[ 0.99688012  1.93860476  1.25643476 -0.03130598 -0.29672348 -0.37054797\n",
      "   0.79676807  1.51879536 -0.05743449 -0.83525916  0.55476713  0.94560795\n",
      "   0.36668798  1.1882422 ]]\n"
     ]
    }
   ],
   "source": [
    "w_est = np.median(qw.sample(10000).eval(),axis=0)\n",
    "print(w_est)\n",
    "print(logit.coef_/1.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = ed.dot(tf.cast(X_test, tf.float32), w_est) + b_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And put them in the Inverse Normal. For efficiency, we put them in the erf (error-function), which has no relation to the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = 0.5 * (1 + tf.erf(Z/ tf.sqrt(2.))).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4440,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we get predictions that are at least similar to logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.98620829],\n",
       "       [0.98620829, 1.        ]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(pred, logit.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit and Probit achieve a very similar AUC on the test data. This is expected, since the models are not very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.791640070602644\n",
      "0.7924568382159967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "print(roc_auc_score(y_test, pred))\n",
    "print(roc_auc_score(y_test, logit.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [edward]",
   "language": "python",
   "name": "Python [edward]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
